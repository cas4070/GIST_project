{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "from urllib2 import urlopen\n",
    "import urllib2\n",
    "import pdb\n",
    "from itertools import product\n",
    "from chemspipy import ChemSpider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the table form of HMDB files. 'path' is the location which HMDB xml files are in. This HMDB xml files  \n",
    "# (path는 HMDB에서 제공하는 zip 파일의 압축을 푼 폴더를 말함. 함수의 입력으로 받으나 여기서는 하드코딩함.)\n",
    "path = \"/home/share/aschoi/nas/users/asolchoi/data/COCONUT_Herbal/4_HMDB/hmdb_metabolites/\"\n",
    "def parse_hmdb_xml(path):\n",
    "    print \"parse the HMDB xml files\"\n",
    "    print \"Start :\" + time.strftime('%a %H:%M:%S')\n",
    "    # 폴더 내의 모든 파일 이름 얻어오기. \n",
    "    file_name = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            file_name.append(f)\n",
    "        \n",
    "    # HMDB00001 부터 시작하게 sort한다.\n",
    "    file_name.sort()\n",
    "\n",
    "    # 마지막은 전체 파일이기 때문에 삭제 한다. # hmdb_metabolites.xml을 제거하기 위해서이다.\n",
    "    del file_name[len(file_name)-1]\n",
    "\n",
    "    #file별 path\n",
    "    file_path=[]\n",
    "    for i in file_name:\n",
    "        file_path.append(path+i)\n",
    "\n",
    "    # xml 파일별로 필요한 정보 파싱\n",
    "    df = pd.DataFrame()\n",
    "    for j in file_path:\n",
    "        #parse xml file\n",
    "        tree = ET.parse(j)\n",
    "        #get root node\n",
    "        xml_root = tree.getroot()\n",
    "        \n",
    "        #필요한 데이터 저장\n",
    "        #accession\n",
    "        accession = xml_root[3].text\n",
    "        #name\n",
    "        if type(xml_root[5].text) == unicode:\n",
    "            name = xml_root[5].text.encode(\"ascii\", \"replace\")\n",
    "        else:\n",
    "            name = xml_root[5].text\n",
    "        #pubchem cid\n",
    "        pubchem_id = xml_root[43].text\n",
    "        #smiles\n",
    "        smiles = xml_root[14].text\n",
    "        #inchi\n",
    "        inchi = xml_root[15].text\n",
    "        #inchikey\n",
    "        inchikey = xml_root[16].text\n",
    "        \n",
    "        temp_df = pd.DataFrame([[accession, name, pubchem_id, smiles, inchi, inchikey]],columns = ['Accession', 'Name', 'PubChem_CID', 'Smiles', 'InchI', 'InchI_key'])\n",
    "        df = df.append(temp_df)\n",
    "    print \"End :\" + time.strftime('%a %H:%M:%S')\n",
    "    df.index = range(0, len(df))\n",
    "    #df.to_csv(\"/home/share\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse the HMDB xml files\n"
     ]
    }
   ],
   "source": [
    "#parse the HMDB xml files\n",
    "temp = parse_hmdb_xml(path)\n",
    "#df_hmdb = preprocess_raw_hmdb(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chemspider_smiles(df):\n",
    "    cs = ChemSpider('3e6c1209-d6af-49a8-8f8c-f9daec87a410')\n",
    "    \n",
    "    df = df.fillna('null')\n",
    "    df.replace('InChIKey=','', regex=True, inplace = True)\n",
    "    \n",
    "    print \"Start :\" + time.strftime('%a %H:%M:%S')\n",
    "    result = pd.DataFrame()\n",
    "    search = pd.DataFrame()\n",
    "    for index, row in df.iterrows():\n",
    "        accession = row['Accession']\n",
    "        name = row['Name']\n",
    "        inchikey = row['InChI_key']\n",
    "        inchi = row['InChI']\n",
    "        smiles = row['Smiles']\n",
    "    \n",
    "        com = cs.simple_search(inchikey)    \n",
    "        if com == []: # inchi key mapping결과 없을 때\n",
    "            temp_df = pd.DataFrame([[accession, name, smiles, inchi]], columns = ['Accession', 'Name', 'Smiles', 'InChI'])\n",
    "            search = search.append(temp_df)\n",
    "        \n",
    "        else:\n",
    "            chem_smiles = com[0].smiles.encode('ascii', 'replace')\n",
    "            temp_df = pd.DataFrame([[accession, name, chem_smiles]], columns = ['Accession', 'Name', 'ChemSpider_Smiles'])\n",
    "            result = result.append(temp_df)\n",
    "    print \"InChI key end :\" + time.strftime('%a %H:%M:%S')\n",
    "\n",
    "    search2 = pd.DataFrame()\n",
    "    for index, row in search.iterrows():\n",
    "        accession = row['Accession']\n",
    "        name = row['Name']\n",
    "        inchi = row['InChI']\n",
    "        smiles = row['Smiles']\n",
    "    \n",
    "        com = cs.simple_search(inchi)\n",
    "    \n",
    "        if com == []: # inchi key mapping결과 없을 때\n",
    "            temp_df = pd.DataFrame([[accession, name, inchi]], columns = ['Accession', 'Name', 'Smiles'])\n",
    "            search2 = search.append(temp_df)\n",
    "        \n",
    "        else:\n",
    "            chem_smiles = com[0].smiles.encode('ascii', 'replace')\n",
    "            temp_df = pd.DataFrame([[accession, name, chem_smiles]], columns = ['Accession', 'Name', 'ChemSpider_Smiles'])\n",
    "            result = result.append(temp_df)\n",
    "    print \"InChI end :\" + time.strftime('%a %H:%M:%S')\n",
    "\n",
    "    for index, row in search2.iterrows():\n",
    "        accession = row['Accession']\n",
    "        name = row['Name']\n",
    "        smiles = row['Smiles']\n",
    "    \n",
    "        com = cs.simple_search(inchi)\n",
    "    \n",
    "        if com == []: # inchi key mapping결과 없을 때\n",
    "            continue\n",
    "    \n",
    "        else:\n",
    "            chem_smiles = com[0].smiles.encode('ascii', 'replace')\n",
    "            temp_df = pd.DataFrame([[accession, name, chem_smiles]], columns = ['Accession', 'Name', 'ChemSpider_Smiles'])\n",
    "            result = result.append(temp_df)        \n",
    "        \n",
    "    result.index = range(len(result))\n",
    "\n",
    "    print \"End :\" + time.strftime('%a %H:%M:%S')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_raw_hmdb(df):\n",
    "    print \"preprocess the HMDB files\"\n",
    "    \n",
    "    #cid 존재하는 hmdb\n",
    "    df_hmdb_cid = df[~df.PubChem_CID.isnull()]\n",
    "\n",
    "    # using UniChem REST API, convert pubchem ID to KEGG ID\n",
    "    df_hmdb = pd.DataFrame()\n",
    "    url_base = 'https://www.ebi.ac.uk/unichem/rest/src_compound_id/'\n",
    "    cnt = 0\n",
    "    print \"pubchem ids of hmdb are converted to KEGG ID start : \" + time.strftime('%a %H:%M:%S')\n",
    "    for index, row in df_hmdb_cid.iterrows():\n",
    "        accession = row['Accession']\n",
    "        name = row['Name']\n",
    "        hmdb_pubchem_id = row['PubChem_CID']\n",
    "        \n",
    "        url = url_base + hmdb_pubchem_id + '/22/6'\n",
    "                   \n",
    "        MAX_ATTEMPTS = 8\n",
    "        for attempt in range(MAX_ATTEMPTS):\n",
    "            try:\n",
    "                f = urlopen(url)\n",
    "            except urllib2.HTTPError, e:\n",
    "                if e.code == 404:\n",
    "                    cnt = cnt + 1\n",
    "                    break\n",
    "                else:\n",
    "                    print 'e.code : %d, url : %s, cnt : d' % (e.code, url, cnt)\n",
    "                    raise\n",
    "            except urllib2.URLError, e:\n",
    "                if e.args[0][0] == 110: # connection time out\n",
    "                    sleep_secs = attempt ** 2\n",
    "                    print e\n",
    "                    print url\n",
    "                    print '  cnt = %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                    print '    Retrying in %d seconds...' % sleep_secs\n",
    "                    time.sleep(sleep_secs)\n",
    "                    continue\n",
    "                else:\n",
    "                    print e\n",
    "                    print '   cnt : %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                    raise\n",
    "            else: # error가 일어나지 않을 때.\n",
    "                raw_data = f.readlines()\n",
    "                f.close()\n",
    "                cnt = cnt + 1\n",
    "                if raw_data[0] == '[]':\n",
    "                    break\n",
    "                else:\n",
    "                    splited = raw_data[0].rstrip(']').lstrip('[').split(',')\n",
    "                    for i in splited:\n",
    "                        kegg_id = i.split(':')[1].lstrip(\"\\\"\").rstrip(\"\\\"}\")\n",
    "                        if kegg_id != 'null':\n",
    "                            temp_df = pd.DataFrame([[accession, name, hmdb_pubchem_id, kegg_id]], columns = ['Accession', 'Name', 'PubChem_CID', 'KEGG_ID'])\n",
    "                            df_hmdb = df_hmdb.append(temp_df)\n",
    "            \n",
    "                break\n",
    "        else: #connection을 8번 시도했는데 안될 경우.\n",
    "            print 'we failed to reconnect 8 times in %s' % url \n",
    "    print \"end : \" + time.strftime('%a %H:%M:%S')\n",
    "    \n",
    "    df_hmdb.index = range(len(df_hmdb))\n",
    "    return df_hmdb          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess the HMDB files\n",
      "pubchem ids of hmdb are converted to KEGG ID start : Thu 17:21:36\n",
      "1000 complete Thu 17:39:00\n",
      "2000 complete Thu 17:56:23\n",
      "3000 complete Thu 18:14:18\n",
      "4000 complete Thu 18:32:03\n",
      "5000 complete Thu 18:49:49\n",
      "<urlopen error [Errno 110] Connection timed out>\n",
      "https://www.ebi.ac.uk/unichem/rest/src_compound_id/53479672/22/6\n",
      "  cnt = 5079, error time : Thu 18:53:20\n",
      "    Retrying in 0 seconds...\n",
      "6000 complete Thu 19:09:42\n",
      "7000 complete Thu 19:27:34\n",
      "8000 complete Thu 19:45:41\n",
      "9000 complete Thu 20:03:54\n",
      "10000 complete Thu 20:22:14\n",
      "11000 complete Thu 20:40:45\n",
      "12000 complete Thu 20:59:04\n",
      "13000 complete Thu 21:17:13\n",
      "14000 complete Thu 21:35:17\n",
      "15000 complete Thu 21:53:18\n",
      "16000 complete Thu 22:11:20\n",
      "end : Thu 22:28:02\n"
     ]
    }
   ],
   "source": [
    "# Make the final form of HMDB files. 'path' is the location which HMDB xml files are in. This HMDB xml files  \n",
    "# (path는 HMDB에서 제공하는 zip 파일의 압축을 푼 폴더를 말함. 함수의 입력으로 받으나 여기서는 하드코딩함.)\n",
    "path = \"/home/share/aschoi/nas/users/asolchoi/data/COCONUT_Herbal/4_HMDB/hmdb_metabolites/\"\n",
    "print \"preprocess the HMDB files\"\n",
    "  \n",
    "# 폴더 내의 모든 파일 이름 얻어오기. \n",
    "file_name = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for f in files:\n",
    "        file_name.append(f)\n",
    "        \n",
    "# HMDB00001 부터 시작하게 sort한다.\n",
    "file_name.sort()\n",
    "\n",
    "# 마지막은 전체 파일이기 때문에 삭제 한다. # hmdb_metabolites.xml을 제거하기 위해서이다.\n",
    "#del file_name[len(file_name)-1]\n",
    "\n",
    "#file별 path\n",
    "file_path=[]\n",
    "for i in file_name:\n",
    "    file_path.append(path+i)\n",
    "\n",
    "# xml 파일별로 필요한 정보 파싱\n",
    "df = pd.DataFrame()\n",
    "for j in file_path:\n",
    "    #parse xml file\n",
    "    tree = ET.parse(j)\n",
    "    #get root node\n",
    "    xml_root = tree.getroot()\n",
    "        \n",
    "    #필요한 데이터 저장\n",
    "    #accession\n",
    "    accession = xml_root[3].text\n",
    "    #name\n",
    "    if type(xml_root[5].text) == unicode:\n",
    "        name = xml_root[5].text.encode(\"ascii\", \"replace\")\n",
    "    else:\n",
    "        name = xml_root[5].text\n",
    "    #pubchem cid\n",
    "    pubchem_id = xml_root[43].text\n",
    "        \n",
    "    temp_df = pd.DataFrame([[accession, name, pubchem_id]],columns = ['Accession', 'Name', 'PubChem_CID'])\n",
    "    df = df.append(temp_df)\n",
    "    \n",
    "df.index = range(0, len(df))        \n",
    "    \n",
    "#cid 존재하는 hmdb\n",
    "df_hmdb_cid = df[~df.PubChem_CID.isnull()]\n",
    "\n",
    "# using UniChem REST API, convert pubchem ID to KEGG ID\n",
    "df_hmdb = pd.DataFrame()\n",
    "url_base = 'https://www.ebi.ac.uk/unichem/rest/src_compound_id/'\n",
    "cnt = 0\n",
    "print \"pubchem ids of hmdb are converted to KEGG ID start : \" + time.strftime('%a %H:%M:%S')\n",
    "for index, row in df_hmdb_cid.iterrows():\n",
    "    accession = row['Accession']\n",
    "    name = row['Name']\n",
    "    hmdb_pubchem_id = row['PubChem_CID']\n",
    "        \n",
    "    url = url_base + hmdb_pubchem_id + '/22/6'\n",
    "    \n",
    "    MAX_ATTEMPTS = 8\n",
    "    for attempt in range(MAX_ATTEMPTS):\n",
    "        try:\n",
    "            f = urlopen(url)\n",
    "        except urllib2.HTTPError, e:\n",
    "            if e.code == 404:\n",
    "                cnt = cnt + 1\n",
    "                break\n",
    "            else:\n",
    "                print 'e.code : %d, url : %s, cnt : d' % (e.code, url, cnt)\n",
    "                raise\n",
    "        except urllib2.URLError, e:\n",
    "            if e.args[0][0] == 110: # connection time out\n",
    "                sleep_secs = attempt ** 2\n",
    "                print e\n",
    "                print url\n",
    "                print '  cnt = %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                print '    Retrying in %d seconds...' % sleep_secs\n",
    "                time.sleep(sleep_secs)\n",
    "                continue\n",
    "            else:\n",
    "                print e\n",
    "                print '   cnt : %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                raise\n",
    "        else: # error가 일어나지 않을 때.\n",
    "            raw_data = f.readlines()\n",
    "            f.close()\n",
    "            cnt = cnt + 1\n",
    "            if raw_data[0] == '[]':\n",
    "                break\n",
    "            else:\n",
    "                splited = raw_data[0].rstrip(']').lstrip('[').split(',')\n",
    "                for i in splited:\n",
    "                    kegg_id = i.split(':')[1].lstrip(\"\\\"\").rstrip(\"\\\"}\")\n",
    "                    if kegg_id != 'null':\n",
    "                        temp_df = pd.DataFrame([[accession, name, hmdb_pubchem_id, kegg_id]], columns = ['Accession', 'Name', 'PubChem_CID', 'KEGG_ID'])\n",
    "                        df_hmdb = df_hmdb.append(temp_df)\n",
    "            \n",
    "            break \n",
    "            \n",
    "    else: #connection을 8번 시도했는데 안될 경우.\n",
    "        print 'we failed to reconnect 8 times in %s' % url \n",
    "    if cnt % 1000 == 0 :\n",
    "        print \"%d complete \"%cnt + time.strftime('%a %H:%M:%S')\n",
    "print \"end : \" + time.strftime('%a %H:%M:%S')\n",
    "    \n",
    "df_hmdb.index = range(len(df_hmdb))\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16923\n",
      "3147\n",
      "16923\n"
     ]
    }
   ],
   "source": [
    "print len(df_hmdb_cid)\n",
    "print len(df_hmdb)\n",
    "print cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hmdb.to_csv(\"/home/share/aschoi/data/COCONUT_Herbal/4_HMDB/HMDB_KEGG_new.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the final form of herbfiles. 'herb_path' is the location which herb file is in. (tsv format)\n",
    "# 'stitch_cid_path' is the path of the STITCH-PubChem CID id mapping file.\n",
    "# raw herb file comes from COCONUT database. columns : (herbID), (herbName), compID, compName, pubchemID, casID, chemblID, stitchID\n",
    "herb_path = \"/home/share/aschoi/nas/users/asolchoi/data/COCONUT_Herbal/6_Herb/COCONUT_herb_compound_ID(remove_duplicate)_tab.txt\"\n",
    "stitch_cid_path = \"/home/share/aschoi/nas/users/asolchoi/data/COCONUT_Herbal/7_Ezyme_tool/STITCH_CID.tsv\"\n",
    "def preprocess_raw_herb(herb_path, stitch_cid_path):\n",
    "    print \"preprocess the raw herb file\"\n",
    "    \n",
    "    df = pd.read_table(herb_path)\n",
    "    df = df.fillna('null')\n",
    "    \n",
    "    ############ pubchemID ############\n",
    "    df_herb = df[df.pubchemID != 'null'][['compID', 'compName', 'pubchemID']]\n",
    "    \n",
    "    ########### stitch #################\n",
    "    df_stitch = df[(df.pubchemID =='null') & (df.stitchID != 'null')]\n",
    "    \n",
    "    # read the pair of STITCH ID - PubChem CID\n",
    "    df_stitch_cid= pd.read_table(stitch_cid_path, index_col = False)\n",
    "    \n",
    "    # find the PubChem CID of STITCH id from STITCH ID - PubChem CID pair\n",
    "    for index, row in df_stitch.iterrows():\n",
    "        compID = row['compID']\n",
    "        compName = row['compName']\n",
    "        stitchID = row['stitchID']\n",
    "        \n",
    "        found = df_stitch_cid[df_stitch_cid.stereo_chemical == stitchID]\n",
    "        pubchemID = found['source_id']\n",
    "        #temp_df = pd.DataFrame([[compID, compName, pubchemID]])\n",
    "    \n",
    "    # read the pair of STITCH ID - PubChem CID\n",
    "    df_stitch_cid= pd.read_table(stitch_cid_path, index_col = False)\n",
    "\n",
    "    # find the PubChem CID of STITCH id from STITCH ID - PubChem CID pair\n",
    "    for index, row in df_stitch.iterrows():\n",
    "        compID = row['compID']\n",
    "        compName = row['compName']\n",
    "        stitchID = row['stitchID']\n",
    "            \n",
    "        found = df_stitch_cid[df_stitch_cid.stereo_chemical == stitchID]\n",
    "        pubchemID = found['source_id']\n",
    "        temp_df = pd.DataFrame({'compID' : compID, 'compName' : compName, 'pubchemID' : pubchemID})\n",
    "        df_herb = df_herb.append(temp_df)\n",
    "    \n",
    "    ########### cas ID ##############\n",
    "    df2_flag = df['compID'].isin(df_herb['compID'].drop_duplicates())\n",
    "    df2 = df[~df2_flag]\n",
    "    df_cas = df2[(df2.pubchemID == 'null') & (df2.casID != 'null')]\n",
    "    \n",
    "    temp = df_cas[df_cas['casID'].str.contains('/')]\n",
    "    for index, row in temp.iterrows():\n",
    "        cas_splited = row['casID'].split('/')\n",
    "        if len(cas_splited[0]) < 2:\n",
    "            cas = cas_splited[2] + '-0' + cas_splited[0] + '-' + cas_splited[1] \n",
    "        else:\n",
    "            cas = cas_splited[2] + '-' + cas_splited[0] + '-' + cas_splited[1] \n",
    "        df_cas.set_value(index,'casID', cas)\n",
    "    \n",
    "    # using chemical translation service REST webservices, convert casID to KEGG ID    \n",
    "    cnt = 0\n",
    "    url_base = 'http://cts.fiehnlab.ucdavis.edu/service/convert/CAS/PubChem%20CID/'    \n",
    "    print \"cas ids of herb compound are converted into pubchem ids start : \" + time.strftime('%a %H:%M:%S')\n",
    "    for index, row in df_cas.iterrows():\n",
    "        compID = row['compID']\n",
    "        compName = row['compName']\n",
    "        casID = row['casID']\n",
    "        \n",
    "        url = url_base + casID\n",
    "                   \n",
    "        MAX_ATTEMPTS = 8\n",
    "        for attempt in range(MAX_ATTEMPTS):\n",
    "            try:\n",
    "                f = urlopen(url)\n",
    "            except urllib2.URLError, e:\n",
    "                if e.args[0][0] == 110: # connection time out\n",
    "                    sleep_secs = attempt ** 2\n",
    "                    print e\n",
    "                    print url\n",
    "                    print '  cnt = %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                    print '    Retrying in %d seconds...' % sleep_secs\n",
    "                    time.sleep(sleep_secs)\n",
    "                    continue\n",
    "                else:\n",
    "                    print e\n",
    "                    print '   cnt : %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                    raise\n",
    "            else: # error가 일어나지 않을 때.\n",
    "                raw_data = json.load(f)\n",
    "                res = raw_data[0]['result']\n",
    "                if res == []: # 못찾음\n",
    "                    cnt = cnt + 1\n",
    "                else:\n",
    "                    cnt = cnt + 1\n",
    "                    pubchemID = res[0].encode(\"ascii\", \"replace\")\n",
    "                    temp_df = pd.DataFrame([[compID, compName, pubchemID]], columns = ['compID','compName','pubchemID'])\n",
    "                    df_herb = df_herb.append(temp_df)\n",
    "                break\n",
    "        else: #connection을 8번 시도했는데 안될 경우.\n",
    "            print 'we failed to reconnect 8 times in %s' % url \n",
    "    print \"end : \" + time.strftime('%a %H:%M:%S')\n",
    "    \n",
    "    df_herb.index = range(len(df_herb))\n",
    "    return df_herb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#open files\n",
    "df_raw_herb_hmdb_pair = pd.read_csv('/home/share/aschoi/data/COCONUT_Herbal/5_Similarity/7_sorted_score_vector_except_1(descending)_top_10_percent_no_score.csv', header=None)\n",
    "#df_hmdb = pd.read_table('/home/share/aschoi/data/COCONUT_Herbal/4_HMDB/HMDB_KEGG.tsv')\n",
    "#df_herb = pd.read_table('/home/share/aschoi/data/COCONUT_Herbal/7_Ezyme_tool/2-5_herb_pubchem.tsv')\n",
    "df_kegg_rpair = pd.read_table('/home/share/aschoi/data/COCONUT_Herbal/1_KEGG_rpair/KEGG_Rpair.txt')\n",
    "df_orthology = pd.read_table('/home/share/aschoi/data/COCONUT_Herbal/7_Ezyme_tool/5_predicted_orthology.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract elements of top percentage.\n",
    "def count_percentage(percentage):\n",
    "    print\"  Count the number of top %.2f %% similar compounds..\" % percentage\n",
    "    WHOLE_LENGTH = 646647053\n",
    "    prepared_idx = 0\n",
    "    percentage_idx = int(WHOLE_LENGTH * percentage / 100)\n",
    "    \n",
    "    if percentage <= 0.1 and percentage > 0 :\n",
    "        df_top_herb_hmdb_pair = df_raw_herb_hmdb_pair[:percentage_idx]\n",
    "        connect = 0\n",
    "        print \"  -> There are %d similar compounds.\" % (prepared_idx + percentage_idx)\n",
    "        #print \"len(df_top_herb_hmdb_pair : %d)\" %len(df_top_herb_hmdb_pair)\n",
    "    elif percentage == 0 or percentage > 10 :\n",
    "        #if percentage > 10 :\n",
    "            #print(\"Input percentage is too big. Count just Top 10%.\")\n",
    "        #else percentage == 0 :\n",
    "            #print(\"Input percentage is not valid.\")\n",
    "        df_top_herb_hmdb_pair = pd.DataFrame()\n",
    "        connect = 1\n",
    "    else :\n",
    "        prepared_idx = int(WHOLE_LENGTH * 0.1 / 100)\n",
    "        df_top_herb_hmdb_pair = df_raw_herb_hmdb_pair[prepared_idx+1:percentage_idx]\n",
    "        connect = 2\n",
    "        print \"There are %d similar compounds.\" % (prepared_idx + percentage_idx)\n",
    "    #print\"len(df_top_herb_hmdb_pair) : %d\" % len(df_top_herb_hmdb_pair)\n",
    "    return connect, df_top_herb_hmdb_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top herb id, top hmdb id\n",
    "def extract_top_id(df_top_herb_hmdb_pair):\n",
    "    s_top_herb = df_top_herb_hmdb_pair['compID']\n",
    "    s_top_hmdb = df_top_herb_hmdb_pair['Accession']\n",
    "    print(\"    1. Extract the ids of top herbal and top HMDB compounds.\")\n",
    "    #print(\"           len(s_top_herb, hmdb) : %d %d\")%(len(s_top_herb), len(s_top_hmdb))\n",
    "    return s_top_herb, s_top_hmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_keggid_of_hmdb(df_hmdb, s_top_hmdb):\n",
    "    # The flag is used to find the KEGG ID of top_similar_hmdb.\n",
    "    flag_find_keggid_of_top_hmdb = df_hmdb['Accession'].isin(s_top_hmdb)\n",
    "\n",
    "    # This dataframe represents the pair of top hmdb id and its KEGG ID.\n",
    "    # This information is used when find the substrate of KEGG rpair which correspond to the top_hmdb.\n",
    "    df_top_hmdb_keggid_pair = df_hmdb[flag_find_keggid_of_top_hmdb][['Accession', 'KEGG_ID']]\n",
    "    print(\"    2. Find the KEGG id of whole top HMDB compounds.\")\n",
    "    #print(\"        len(df_top_hmdb_keggid_pair) : %d\") % len(df_top_hmdb_keggid_pair)\n",
    "    return df_top_hmdb_keggid_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glob_top_herb_pubchemid_pair = 0;\n",
    "def find_pubchemid_of_herb(df_herb, s_top_herb):\n",
    "    # The flag is used to find the PubChem ID of top_herb.\n",
    "    flag_find_pubchemid_of_top_herb = df_herb['compID'].isin(s_top_herb)\n",
    "\n",
    "    # This dataframe represents the pair of top herb id and its PubChem ID.\n",
    "    # Using this information, we can predict the orphan herbs' ontology.\n",
    "    # One pubchem id of herb becomes the input substrate of KEGG E-zyme2 tool.\n",
    "    df_top_herb_pubchemid_pair = df_herb[flag_find_pubchemid_of_top_herb][['compID', 'pubchemID']]\n",
    "    print(\"    3. Find the PubChem id of top herbal compounds.\")\n",
    "    #print(\"        len(df_top_herb_pubchemid_pair) : %d\") % len(df_top_herb_pubchemid_pair)\n",
    "    glob_top_herb_pubchemid_pair = df_top_herb_pubchemid_pair\n",
    "    return df_top_herb_pubchemid_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the rpairs whose substrate is same to the top_hmdb.\n",
    "# The pair is represented by only KEGG ID. (NOT hmdb_id.)\n",
    "def find_kegg_rpair_of_hmdb_sub(df_kegg_rpair, df_top_hmdb_keggid_pair):\n",
    "    flag_find_rpair_of_top_hmdb_sub = df_kegg_rpair['Compound1'].isin(df_top_hmdb_keggid_pair['KEGG_ID']) \n",
    "\n",
    "    # This dataframe consist of KEGG ID.\n",
    "    df_rpair_of_top_hmdb_sub_k = df_kegg_rpair[flag_find_rpair_of_top_hmdb_sub]\n",
    "    print(\"    4. Find the KEGG rpair whose substrate is same to the top hmdb compounds.\")\n",
    "    #print(\"        len(df_rpair_of_top_hmdb_sub_k) : %d\") % len(df_rpair_of_top_hmdb_sub_k)\n",
    "    #print sum(flag_find_rpair_of_top_hmdb_sub)\n",
    "    #print len(df_rpair_of_top_hmdb_sub_k)\n",
    "    #print len(df_rpair_of_top_hmdb_sub_k['Compound1'].drop_duplicates())\n",
    "    return df_rpair_of_top_hmdb_sub_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the part of top_hmdb. \n",
    "# It have KEGG ID which corresponds to the substrate of KEGG rpair.\n",
    "# Why need this process? \n",
    "# Because we don't have the pair of the kegg_id version substrate(although it corresponds to the top_hmdb!) and top_hmdb id.\n",
    "\n",
    "def find_keggid_of_top_hmdb2(df_top_hmdb_keggid_pair, df_rpair_of_top_hmdb_sub_k):\n",
    "\n",
    "    flag_find_hmdbid_of_top_hmdb_sub = df_top_hmdb_keggid_pair['KEGG_ID'].isin(df_rpair_of_top_hmdb_sub_k['Compound1'])\n",
    "    df_top_hmdb_of_sub = df_top_hmdb_keggid_pair[flag_find_hmdbid_of_top_hmdb_sub]\n",
    "    print(\"    5. Find some HMDB compounds which corresponds to the substrate of KEGG rpair.\")\n",
    "    #print(\"        len(df_top_hmdb_of_sub) : %d\") % len(df_top_hmdb_of_sub)\n",
    "    #print sum(flag_find_hmdbid_of_top_hmdb_sub)\n",
    "    #print len(df_top_hmdb_of_sub)\n",
    "    #print len(df_top_hmdb_of_sub['Accession'].drop_duplicates())\n",
    "    #print len(df_top_hmdb_of_sub['KEGG_ID'].drop_duplicates())\n",
    "    return df_top_hmdb_of_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the pair of top_hmdb and top_herb.\n",
    "# The top_hmdb is the substrate of the KEGG rpair.\n",
    "# The top_herb is the similar herbal compounds of the top_hmdb.\n",
    "def find_candidate_substrate(df_top_herb_hmdb_pair, df_top_hmdb_of_sub, df_top_herb_pubchemid_pair):\n",
    "    flag_find_sim_herb_of_hmdb_sub = df_top_herb_hmdb_pair['Accession'].isin(df_top_hmdb_of_sub['Accession'])\n",
    "    df_sim_herb_of_hmdb_sub = df_top_herb_hmdb_pair[flag_find_sim_herb_of_hmdb_sub]\n",
    "    \n",
    "    # Find the pubchem id of the herbs which is similar to the hmdb compounds. These hmdb compounds are the substrate of rpair. \n",
    "    flag_find_pubchemid_of_sim_herb =df_top_herb_pubchemid_pair['compID'].isin(df_sim_herb_of_hmdb_sub['compID'])\n",
    "    df_sim_herb_pubchem_id_pair = df_top_herb_pubchemid_pair[flag_find_pubchemid_of_sim_herb]\n",
    "\n",
    "    df_candidate_sub_herb = pd.merge(df_top_hmdb_of_sub, df_sim_herb_of_hmdb_sub, how = 'inner', on = ['Accession', 'Accession'])\n",
    "    df_candidate_sub_herb_pubchem = pd.merge(df_candidate_sub_herb, df_sim_herb_pubchem_id_pair, how='inner', on=['compID', 'compID'])\n",
    "    \n",
    "    print(\"    6. Find the candidate herbal compounds which is similar to HMDB's substrates.\")\n",
    "    #print(\"        len(df_candidate_sub_herb_pubchem) : %d\") % len(df_candidate_sub_herb_pubchem)\n",
    "    return df_candidate_sub_herb_pubchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the pair of herb(used to be substrate) and product.\n",
    "# If the pair will exist in the prepared orthology table, just show the predicted_result.\n",
    "# Unless the pair will not exist in the prepared table, we have to crawl the predicted reusult from KEGG E-zyme2 webpage.\n",
    "def query_list(df_candidate_sub_herb_pubchem, df_rpair_of_top_hmdb_sub_k):\n",
    "    #print \"       inner query_list : len(df_candidate_sub_herb_pubchem, df_rpair_of_top_hmdb_sub_k) %d, %d\" % (len(df_candidate_sub_herb_pubchem), len(df_rpair_of_top_hmdb_sub_k))\n",
    "    s_candidate_keggid = df_candidate_sub_herb_pubchem['KEGG_ID'].drop_duplicates()\n",
    "    #print \"       len(s_candidate_keggid) : %d\" % len(s_candidate_keggid)\n",
    "    df_query = pd.DataFrame()\n",
    "    for i in s_candidate_keggid:\n",
    "        df_candidate_sub_part = df_candidate_sub_herb_pubchem[df_candidate_sub_herb_pubchem.KEGG_ID == i]\n",
    "        df_candidate_pro_part = df_rpair_of_top_hmdb_sub_k[df_rpair_of_top_hmdb_sub_k.Compound1 == i]\n",
    "        s_candidate_sub_part = df_candidate_sub_part['pubchemID']\n",
    "        s_candidate_pro_part = df_candidate_pro_part['Compound2']\n",
    "        temp_df = pd.DataFrame(list(product(s_candidate_sub_part, s_candidate_pro_part)), columns = ['substrate', 'product'])\n",
    "        df_query = df_query.append(temp_df)\n",
    "    df_query = df_query.drop_duplicates()\n",
    "    df_query.index = range(0, len(df_query))\n",
    "    print(\"    7. Make the query lists of the candidate rpair which will be predicted.\")\n",
    "    #print(\"        len(df_query) : %d\") % len(df_query)\n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_query_result(df_query, df_orthology):\n",
    "    #print(\"start match query result : \" + time.strftime('%a %H:%M:%S'))\n",
    "    predict_result = pd.DataFrame()\n",
    "    for index, row in df_query.iterrows():\n",
    "        query = row.tolist()\n",
    "        #result = df_orthology.query('@query[0] == substrate and @query[1] == product')\n",
    "        result = df_orthology[(df_orthology.substrate == query[0]) & (df_orthology['product'].str.match(query[1]))]\n",
    "        if result.empty:\n",
    "            continue\n",
    "        else:\n",
    "            predict_result = predict_result.append(result)\n",
    "            #pdb.set_trace()\n",
    "    predict_result.index = range(0, len(predict_result))    \n",
    "    #print(\"end match query result\" + time.strftime('%a %H:%M:%S'))\n",
    "    print(\"    8. Find the predicted orthology of the query rpair.\")\n",
    "    return predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def make_query_list(top_herb, top_hmdb):\n",
    "def make_query_list(df_top_herb_hmdb_pair):\n",
    "    \n",
    "    \n",
    "    df_top_herb_hmdb_pair = df_top_herb_hmdb_pair.rename(columns={0:'compID', 1:'Accession'})\n",
    "    s_top_herb, s_top_hmdb = extract_top_id(df_top_herb_hmdb_pair)\n",
    "    \n",
    "    # Find the KEGG ID of top_hmdb.\n",
    "    df_top_hmdb_keggid_pair = find_keggid_of_hmdb(df_hmdb, s_top_hmdb)\n",
    "    \n",
    "    # Find the PubChem ID of top_herb.\n",
    "    df_top_herb_pubchemid_pair = find_pubchemid_of_herb(df_herb, s_top_herb)\n",
    "    \n",
    "    # Find the rpairs whose substrate is same to the top_hmdb.\n",
    "    df_rpair_of_top_hmdb_sub_k = find_kegg_rpair_of_hmdb_sub(df_kegg_rpair, df_top_hmdb_keggid_pair)\n",
    "    \n",
    "    # Find the part of top_hmdb. \n",
    "    df_top_hmdb_of_sub = find_keggid_of_top_hmdb2(df_top_hmdb_keggid_pair, df_rpair_of_top_hmdb_sub_k)\n",
    "    \n",
    "    # Find the pair of top_hmdb and top_herb.\n",
    "    df_candidate_sub_herb_pubchem = find_candidate_substrate(df_top_herb_hmdb_pair, df_top_hmdb_of_sub, df_top_herb_pubchemid_pair)\n",
    "    #print \"       before query_list : len(df_candidate_sub_herb_pubchem, df_rpair_of_top_hmdb_sub_k) %d, %d\" % (len(df_candidate_sub_herb_pubchem), len(df_rpair_of_top_hmdb_sub_k))\n",
    "    # Make the pair of herb(used to be substrate) and product.\n",
    "    df_query = query_list(df_candidate_sub_herb_pubchem, df_rpair_of_top_hmdb_sub_k)\n",
    "    \n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_predicted_result(predicted_result, df_herb):\n",
    "    herb_predicted_result = pd.merge(left = df_herb, right = predicted_result, left_on = 'pubchemID', right_on = 'substrate')\n",
    "    herb_predicted_result = herb_predicted_result.rename(columns={'compID':'COCONUT_herb_compound_id',\n",
    "                                                                  'compName':'COCONUT_herb_compound_name',\n",
    "                                                                  'pubchemID' : 'COCONUT_herb_compound_PubChem_id' })\n",
    "    print herb_predicted_result\n",
    "    return herb_predicted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def web_ezyme(df_query):\n",
    "    print \"    9. The number of crawling pairs : %d \" % len(df_query)\n",
    "    predicted_result2 = pd.DataFrame()\n",
    "    cnt = 0\n",
    "    url_base = 'http://rest.genome.jp/ezyme/'\n",
    "    \n",
    "    for index, row in df_query[cnt:].iterrows():\n",
    "        sub = int(row['substrate'])\n",
    "        pro = row['product']\n",
    "        url = url_base + 'CID'+str(sub) +'/' + pro\n",
    "        \n",
    "        MAX_ATTEMPTS = 8\n",
    "        for attempt in range(MAX_ATTEMPTS):\n",
    "            try:\n",
    "                f = urlopen(url)\n",
    "            except urllib2.HTTPError, e:\n",
    "                if e.code == 404:\n",
    "                    print 'HTTPError 404 not found %d : ' % cnt + time.strftime('%a %H:%M:%S')\n",
    "                    print url\n",
    "                    cnt = cnt + 1\n",
    "                    break\n",
    "                else:\n",
    "                    print 'e.code : %d, url : %s, cnt : d' % (e.code, url, cnt)\n",
    "                    raise\n",
    "            except urllib2.URLError, e:\n",
    "                if e.args[0][0] == 110: # connection time out\n",
    "                    sleep_secs = attempt ** 2\n",
    "                    print e\n",
    "                    print '  cnt = %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                    print urll\n",
    "                    print '    Retrying in %d seconds...' % sleep_secs\n",
    "                    time.sleep(sleep_secs)\n",
    "                    continue\n",
    "                else:\n",
    "                    print e\n",
    "                    print '   cnt : %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                    raise\n",
    "            else:          \n",
    "                all_data = f.readlines()\n",
    "                data = all_data[1].split('\\t')\n",
    "                predicted_orthology = data[1]\n",
    "                predicted_score = data[0]        \n",
    "                temp_df = pd.DataFrame([[sub, pro, predicted_orthology, predicted_score]], columns = ['substrate', 'product', 'predicted_orthology', 'predicted_score'])\n",
    "                predicted_result2 = predicted_result2.append(temp_df)\n",
    "                cnt = cnt + 1\n",
    "                break\n",
    "        else:\n",
    "            print 'we failed to reconnect 8 times in %s' % url \n",
    "        \n",
    "        #if cnt % 1000 == 0 :\n",
    "        #    print '%d : '% cnt + time.strftime('%a %H:%M:%S')\n",
    "    #print time.strftime('%a %H:%M:%S')\n",
    "    predicted_result2.index = range(0, len(predicted_result2))\n",
    "    return predicted_result2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess the HMDB files\n",
      "pubchem ids of hmdb are converted to KEGG ID start : Thu 10:07:23\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/92105/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/11266/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/53477676/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/6451121/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/1125/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/12306765/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/440567/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/24758425/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/657311/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/11025495/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/849/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/9860744/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/71920/22/6\n",
      "we failed to reconnect 8 times in https://www.ebi.ac.uk/unichem/rest/src_compound_id/22833510/22/6\n",
      "end : Thu 10:10:29\n"
     ]
    }
   ],
   "source": [
    "hmdb_path = \"/home/share/aschoi/nas/users/asolchoi/data/COCONUT_Herbal/4_HMDB/hmdb_metabolites/\"\n",
    "df_hmdb =  preprocess_raw_hmdb(hmdb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess the raw herb file\n",
      "cas ids of herb compound are converted into pubchem ids start : Thu 23:43:04\n",
      "end : Fri 00:05:09\n"
     ]
    }
   ],
   "source": [
    "herb_path = \"/home/share/aschoi/nas/users/asolchoi/data/COCONUT_Herbal/6_Herb/COCONUT_herb_compound_ID(remove_duplicate)_tab.txt\"\n",
    "stitch_cid_path = \"/home/share/aschoi/nas/users/asolchoi/data/COCONUT_Herbal/7_Ezyme_tool/STITCH_CID.tsv\"\n",
    "df_herb = preprocess_raw_herb(herb_path, stitch_cid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compID</th>\n",
       "      <th>compName</th>\n",
       "      <th>pubchemID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10237</td>\n",
       "      <td>Phenol</td>\n",
       "      <td>20488062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52815</td>\n",
       "      <td>(2R,3R)-2-(3,4-Dihydroxyphenyl)-3,7-dihydroxy-...</td>\n",
       "      <td>10343835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62077</td>\n",
       "      <td>(2E)-3-{2-Hydroxy-4-[(2R,3R)-3-(hydroxymethyl)...</td>\n",
       "      <td>6438693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62076</td>\n",
       "      <td>(13alpha,14beta,17alpha,20S,21R,23R,24S)-21-Hy...</td>\n",
       "      <td>44575793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67348</td>\n",
       "      <td>(5xi,9xi,13xi,14xi,17xi,20xi)-21-Acetoxy-21,23...</td>\n",
       "      <td>5321231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compID                                           compName pubchemID\n",
       "0   10237                                             Phenol  20488062\n",
       "1   52815  (2R,3R)-2-(3,4-Dihydroxyphenyl)-3,7-dihydroxy-...  10343835\n",
       "2   62077  (2E)-3-{2-Hydroxy-4-[(2R,3R)-3-(hydroxymethyl)...   6438693\n",
       "3   62076  (13alpha,14beta,17alpha,20S,21R,23R,24S)-21-Hy...  44575793\n",
       "4   67348  (5xi,9xi,13xi,14xi,17xi,20xi)-21-Acetoxy-21,23...   5321231"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(df_herb)\n",
    "df_herb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Main ###########\n",
    "\n",
    "# aceeptuser input\n",
    "percentage = input('Enter the percentage number (0,10] : ')\n",
    "connect, df_top_herb_hmdb_pair = count_percentage(percentage)\n",
    "\n",
    "if connect == 1: #Input is not valid.\n",
    "    print(\"Input is not valid. Stop the program.\")\n",
    "\n",
    "else:\n",
    "    df_query = make_query_list(df_top_herb_hmdb_pair)\n",
    "    \n",
    "    if connect == 2: # Web crawling\n",
    "        print(\"Need to connect the web. time consuming.. : \" + time.strftime('%a %H:%M:%S'))\n",
    "        predicted_result = web_ezyme(df_query)\n",
    "        print(\"End of web crawling : \" + time.strftime('%a %H:%M:%S'))\n",
    "        predicted_result = predicted_result.append(df_orthology) # prepared result (percentage under 0.1%)\n",
    "        print(\"There are %d predicted orthology results.\") % len(predicted_result)\n",
    "    \n",
    "    else: # Matching\n",
    "        if percentage == 0.1:\n",
    "            predicted_result = df_orthology\n",
    "        else:\n",
    "            predicted_result = match_query_result(df_query, df_orthology)\n",
    "        print(\"There are %d predicted orthology results.\") % len(predicted_result)\n",
    "        predictied_result.to_csv(\"/home/share/aschoi/data/COCONUT_Herbal/7_Ezyme_tool/e_zyme_tool_output.tsv\", sep='\\t',index=False)\n",
    "        #a = show_predicted_result(predicted_result, df_herb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "herb_path = \"/home/share/aschoi/nas/users/asolchoi/data/COCONUT_Herbal/6_Herb/COCONUT_herb_compound_ID(remove_duplicate)_tab.txt\"\n",
    "stitch_cid_path = \"/home/share/aschoi/nas/users/asolchoi/data/COCONUT_Herbal/7_Ezyme_tool/STITCH_CID.tsv\"\n",
    "\n",
    "df = pd.read_table(herb_path)\n",
    "df_stitch = df[(df.pubchemID =='null') & (df.stitchID != 'null')]\n",
    "\n",
    "# read the pair of STITCH ID - PubChem CID\n",
    "df_stitch_cid= pd.read_table(stitch_cid_path, index_col = False)\n",
    "\n",
    "df_herb = pd.DataFrame()\n",
    "\n",
    "# find the PubChem CID of STITCH id from STITCH ID - PubChem CID pair\n",
    "for index, row in df_stitch.iterrows():\n",
    "    compID = row['compID']\n",
    "    compName = row['compName']\n",
    "    stitchID = row['stitchID']\n",
    "        \n",
    "    found = df_stitch_cid[df_stitch_cid.stereo_chemical == stitchID]\n",
    "    pubchemID = found['source_id']\n",
    "    temp_df = pd.DataFrame({'compID' : compID, 'compName' : compName, 'pubchemID' : pubchemID})\n",
    "    df_herb = df_herb.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cas ID\n",
    "df2_flag = df['compID'].isin(df_herb['compID'].drop_duplicates())\n",
    "df2 = df[~df2_flag]\n",
    "df_cas = df2[(df2.pubchemID == 'null') & (df2.casID != 'null')]\n",
    "\n",
    "temp = df_cas[df_cas['casID'].str.contains('/')]\n",
    "for index, row in temp.iterrows():\n",
    "    cas_splited = row['casID'].split('/')\n",
    "    if len(cas_splited[0]) < 2:\n",
    "        cas = cas_splited[2] + '-0' + cas_splited[0] + '-' + cas_splited[1] \n",
    "    else:\n",
    "        cas = cas_splited[2] + '-' + cas_splited[0] + '-' + cas_splited[1] \n",
    "    df_cas.set_value(index,'casID', cas)\n",
    "    \n",
    "# using chemical translation service REST webservices, convert casID to KEGG ID    \n",
    "cnt = 0\n",
    "url_base = 'http://cts.fiehnlab.ucdavis.edu/service/convert/CAS/PubChem%20CID/'    \n",
    "print time.strftime('%a %H:%M:%S')\n",
    "for index, row in df_cas.iterrows():\n",
    "        compID = row['compID']\n",
    "        compName = row['compName']\n",
    "        casID = row['casID']\n",
    "        \n",
    "        url = url_base + casID\n",
    "                   \n",
    "        MAX_ATTEMPTS = 8\n",
    "        for attempt in range(MAX_ATTEMPTS):\n",
    "            try:\n",
    "                f = urlopen(url)\n",
    "            except urllib2.URLError, e:\n",
    "                if e.args[0][0] == 110: # connection time out\n",
    "                    sleep_secs = attempt ** 2\n",
    "                    print e\n",
    "                    print url\n",
    "                    print '  cnt = %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                    print '    Retrying in %d seconds...' % sleep_secs\n",
    "                    time.sleep(sleep_secs)\n",
    "                    continue\n",
    "                else:\n",
    "                    print e\n",
    "                    print '   cnt : %d, error time : ' % (cnt) + time.strftime('%a %H:%M:%S')\n",
    "                    raise\n",
    "            else: # error가 일어나지 않을 때.\n",
    "                raw_data = json.load(f)\n",
    "                res = raw_data[0]['result']\n",
    "                if res == []: # 못찾음\n",
    "                    cnt = cnt + 1\n",
    "                else:\n",
    "                    cnt = cnt + 1\n",
    "                    pubchemID = res[0].encode(\"ascii\", \"replace\")\n",
    "                    temp_df = pd.DataFrame([[compID, compName, pubchemID]], columns = ['compID','compName','pubchemID'])\n",
    "                    df_hmdb.append(temp_df)\n",
    "                break\n",
    "        else: #connection을 8번 시도했는데 안될 경우.\n",
    "            print 'we failed to reconnect 8 times in %s' % url \n",
    "print time.strftime('%a %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
