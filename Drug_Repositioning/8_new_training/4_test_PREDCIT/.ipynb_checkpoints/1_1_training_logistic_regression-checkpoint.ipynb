{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, average_precision_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df =pd.read_table(\"/DAS_Storage1/aschoi/data/Drug_Repositioning/8_new_training/5_PREDICT_descriptor/test_pos_descriptor.tsv\")\n",
    "x_whole_data = df[df.columns.values[3:].tolist()].values\n",
    "y_whole_data = df['association'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, average_precision_score\n",
    "\n",
    "def Logist_Regression_10_fold(x_whole_data, y_whole_data, user_c):\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True) # n_splits = 10 (10 fold라서.) data가 nega : pos = 76 : 1이기 때문에 validation 뽑을때 그 비율 지켜서 stratified로 한다.\n",
    "    whole_accuracy = list()\n",
    "    whole_auc = list()\n",
    "    whole_aupr = list()\n",
    "    whole_confusion_mat = list()\n",
    "    for training_index, validation_index in skf.split(x_whole_data, y_whole_data):\n",
    "        #print(\"{}----------------------------------------------------\".format(user_c))\n",
    "        x_training_set = x_whole_data[training_index] # 0.9에 해당하는 부분\n",
    "        y_training_set = y_whole_data[training_index]\n",
    "        x_validation_set = x_whole_data[validation_index] # 0.1에 해당하는 부분\n",
    "        y_validation_set = y_whole_data[validation_index]\n",
    "\n",
    "        classifier = LogisticRegression(penalty='l1', C=user_c, n_jobs=-1) #n_jobs = -1이면 모든 node 쓰는것. 신경쓰이면 30개 정도.\n",
    "        #classifier = RandomForestClassifier(n_estimators=120, n_jobs=-1, class_weight='balanced')\n",
    "        #classifier = LinearSVC(penalty='l1', C=user_c, class_weight='balanced', dual=True, loss='hinge')\n",
    "        classifier.fit(x_training_set, y_training_set)\n",
    "        y_predicted_proba = classifier.predict_proba(x_validation_set) # return값이 probability 각각에 대한 확률 결과값 [[0.8(0에대한 확률),0.2(1에대한 확률)],[0.7,0.3],... ]\n",
    "        y_predicted_label = classifier.predict(x_validation_set) # return이 label임. 위 확률 결과에서 확률이 높은거에 대한 label을 보여줌.\n",
    "\n",
    "        current_accuracy = classifier.score(x_validation_set, y_validation_set) # accuracy score를 보여줌.\n",
    "        fpr, tpr, thresholds = roc_curve(y_validation_set, y_predicted_proba[:, 1], pos_label=1) # powitive label만 본것.\n",
    "        current_auc = auc(fpr, tpr)\n",
    "        current_confusion_matrix = confusion_matrix(y_validation_set,\n",
    "                                                    y_predicted_label)\n",
    "        current_aupr = average_precision_score(y_validation_set, y_predicted_proba[:, 1])\n",
    "    \n",
    "        whole_accuracy.append(current_accuracy)\n",
    "        whole_auc.append(current_auc)\n",
    "        whole_aupr.append(current_aupr)\n",
    "        whole_confusion_mat.append((current_confusion_matrix))\n",
    "        \n",
    "        #print(\"Accuracy of this fold: {}\".format(current_accuracy))\n",
    "        #print(\"AUC of this fold: {}\".format(current_auc))\n",
    "        #print(\"AUPR of this fold: {}\".format(current_aupr))\n",
    "        #print(\"Confustion matrix of this fold\")\n",
    "        #print(current_confusion_matrix)\n",
    "        #print(\"\\n\")\n",
    "    avg_acc = sum(whole_accuracy)/len(whole_accuracy)\n",
    "    avg_auc = sum(whole_auc)/len(whole_auc)\n",
    "    avg_aupr = sum(whole_aupr)/len(whole_aupr)\n",
    "    sum_confusion_matrix = sum(whole_confusion_mat)\n",
    "    #print(\"Accuracy avg : {}\").format(sum(whole_accuracy)/len(whole_accuracy))\n",
    "    #print(\"AUC avg : {}\").format(sum(whole_auc)/len(whole_auc))\n",
    "    #print(\"AUPR avg : {}\").format(sum(whole_aupr)/len(whole_aupr))\n",
    "    #print(\"Confustion matrix\")\n",
    "    #print(sum(whole_confusion_mat))\n",
    "    \n",
    "    return [avg_acc, avg_auc, avg_aupr, sum_confusion_matrix]   \n",
    "    #return [whole_accuracy, whole_auc, whole_aupr, whole_confusion_mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_output(filedescritor, results):\n",
    "    f.write(\"Accuracy avg : {}\\r\\n\".format(results[0]))\n",
    "    f.write(\"AUC avg : {}\\r\\n\".format(results[1]))\n",
    "    f.write(\"AUPR avg : {}\\r\\n\".format(results[2]))\n",
    "    f.write(\"confusion amtrix : {}\\r\\n\".format(results[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print time.strftime('%a %H:%M:%S')\n",
    "with open(\"/home/share/aschoi/nas/users/asolchoi/data/Drug_Repositioning/8_new_training/5_PREDICT_descriptor/1_1_original_10-fold.txt\", 'w') as f :\n",
    "    for user_c in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "        results = Logist_Regression_10_fold(x_whole_data, y_whole_data, user_c)\n",
    "        f.write(\"{}----------------------------------------------------\\r\\n\".format(user_c))\n",
    "        write_output(f, results)\n",
    "print time.strftime('%a %H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
