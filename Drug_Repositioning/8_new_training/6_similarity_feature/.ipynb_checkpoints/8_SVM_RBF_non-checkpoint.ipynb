{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score # AUC score\n",
    "from sklearn.metrics import average_precision_score # AUPR score\n",
    "from sklearn.metrics import precision_recall_fscore_support # precision, recall\n",
    "from imblearn.metrics import sensitivity_specificity_support # sensitivity, specificity\n",
    "from sklearn.metrics import roc_curve # to draw auc curve\n",
    "from sklearn.metrics import precision_recall_curve # to draw aupr curve\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold_pos = pd.read_table(\"/DAS_Storage1/aschoi/data/Drug_Repositioning/data/desc_12/gold_pos_desc12.tsv\")\n",
    "gold_neg = pd.read_table(\"/DAS_Storage1/aschoi/data/Drug_Repositioning/data/desc_12/gold_neg_desc12.tsv\")\n",
    "gold = pd.concat([gold_pos, gold_neg])\n",
    "x_whole_data = gold[gold.columns.values[3:].tolist()].values\n",
    "y_whole_data = gold[\"association\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indep = pd.read_table(\"/DAS_Storage1/aschoi/data/Drug_Repositioning/data/desc_12/indep_desc12.tsv\")\n",
    "indep_x = indep.values[:, 3:].astype(float)\n",
    "indep_y = indep.values[:,2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# undersampler\n",
    "rus = RandomUnderSampler(ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-03 20:51:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# SVM_cubic_K_fold_grpah + 파일 입출력 2017.6.2.\n",
    "print datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "all = Trial()\n",
    "#all.param={'c':0, 'kernel' : 'poly', 'degree' : 2, 'k' : 10, 'tridx' : tridx, 'vaidx' : vaidx}\n",
    "#all.param={'c':0, 'kernel' : 'poly', 'degree' : 2, 'k' : 10, 'tridxs' : tridxs, 'vaidxs' : vaidxs}\n",
    "all.param={'c':0, 'kernel' : 'linear', 'degree' : 3, 'k' : 10}\n",
    "all.param_results = {0.0001:[], 0.001:[], 0.01:[], 0.1:[], 1:[], 10:[], 100:[], 1000:[], 10000:[]}\n",
    "all.draw_total = {0.0001:[], 0.001:[], 0.01:[], 0.1:[], 1:[], 10:[], 100:[], 1000:[], 10000:[]}\n",
    "all.final_param_results = {0.0001:[], 0.001:[], 0.01:[], 0.1:[], 1:[], 10:[], 100:[], 1000:[], 10000:[]}\n",
    "indepndent_count = 10 \n",
    "path = '/home/share/aschoi/nas/users/asolchoi/data/Drug_Repositioning/8_new_training/7_non/'\n",
    "with open(path + \"700_SVM(cubic)_all_desc_training.txt\", 'w') as fd :\n",
    "    fd.write(\"<10 times independent test : undersampling>\\r\\n\")\n",
    "    for key in range(indepndent_count):\n",
    "        all.param['key'] = key\n",
    "        x_resampled, y_resampled = rus.fit_sample(x_whole_data, y_whole_data)\n",
    "        for user_c in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]:\n",
    "                all.param['c'] = user_c\n",
    "                all.folds_results, all.draw_results = all.SVM_K_fold_graph(x_resampled, y_resampled, all.param)\n",
    "                all.avg_result = all.average_result(all.folds_results) # parameter 별로 K-fold한 결과와 average를 구한다.\n",
    "                all.param_results[user_c].append(all.avg_result) # parameter 별로 indepedent 결과 저장한다.\n",
    "                all.draw_total[user_c].append(all.draw_results)\n",
    "\n",
    "    for user_c in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]: #independent 결과를 parameter별로 평균 낸다.\n",
    "        all.indep_results = all.independent_results(all.param_results[user_c])\n",
    "        all.final_param_results[user_c] = all.final_results(all.indep_results)\n",
    "        all.draw_plot(all.draw_total[user_c],all.final_param_results[user_c], user_c)\n",
    "        all.write_output(fd, all.final_param_results[user_c], user_c)\n",
    "    print datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trial :\n",
    "  \n",
    "    def SVM_K_fold_graph(self, X, y, user_parameter):\n",
    "    \n",
    "        skf = StratifiedKFold(n_splits=user_parameter['k'], shuffle=True) # n_splits = k (k fold라서.), pos:neg의 비율을 고려해서 k 개의 subgroup으로 나누어줌.\n",
    "        folds_results = {'acc':[], 'auc':[], 'aupr':[], 'confusion_matrix':[], 'sn':[], 'sp':[], 'precision':[], 'recall':[]}\n",
    "        draw_results = {'fpr':[], 'tpr':[], 'precision_vec':[], 'recall_vec':[]}\n",
    "        for training_index, validation_index in skf.split(X, y):\n",
    "                    \n",
    "        #for training_index, validation_index in zip(user_parameter['tridx'], user_parameter['vaidx']):\n",
    "        #for training_index, validation_index in zip(user_parameter['tridxs'][user_parameter['key']], user_parameter['vaidxs'][user_parameter['key']]):\n",
    "            x_training_set = X[training_index]\n",
    "            y_training_set = y[training_index]\n",
    "            x_validation_set = X[validation_index]\n",
    "            y_validation_set = y[validation_index]\n",
    "\n",
    "            classifier = SVC(C=user_parameter['c'], kernel= user_parameter['kernel'], degree=user_parameter['degree'], probability=True, cache_size=1000) #n_jobs=-1 이면 모든 node 쓰는것, 신경쓰이면 30개 정도.\n",
    "            classifier.fit(x_training_set, y_training_set)\n",
    "\n",
    "            y_predicted_proba = classifier.predict_proba(x_validation_set) # [0에 대한 확률, 1에 대한 확률], shpae = [n_samples, n_class]\n",
    "            y_predicted_label = classifier.predict(x_validation_set) # 예측된 label을 보여줌, shpae = [n_samples]\n",
    "\n",
    "            # Accuracy \n",
    "            current_acc = classifier.score(x_validation_set, y_validation_set)\n",
    "            folds_results['acc'].append(current_acc)\n",
    "\n",
    "            # AUC\n",
    "            current_auc = roc_auc_score(y_validation_set, y_predicted_proba[:,1])\n",
    "            folds_results['auc'].append(current_auc)\n",
    "\n",
    "            # Sensitivity, Specificity\n",
    "            sn, sp, support = sensitivity_specificity_support(y_validation_set, y_predicted_label)\n",
    "            folds_results['sn'].append(sn)\n",
    "            folds_results['sp'].append(sp)\n",
    "\n",
    "            # AUPR\n",
    "            current_aupr = average_precision_score(y_validation_set, y_predicted_proba[:,1])\n",
    "            folds_results['aupr'].append(current_aupr)\n",
    "\n",
    "            # Precision, Recall\n",
    "            precision, recall, _, _ =  precision_recall_fscore_support(y_validation_set, y_predicted_label, average = 'binary')\n",
    "            folds_results['precision'].append(precision)\n",
    "            folds_results['recall'].append(recall)\n",
    "\n",
    "            # Confusion Matrix\n",
    "            current_confusion_matrix = confusion_matrix(y_validation_set,y_predicted_label)\n",
    "            folds_results['confusion_matrix'].append(current_confusion_matrix)\n",
    "\n",
    "            #draw graph\n",
    "            fpr, tpr, thresholds = roc_curve(y_validation_set, y_predicted_proba[:, 1], pos_label=1)\n",
    "            draw_results['fpr'].append(fpr)\n",
    "            draw_results['tpr'].append(tpr)\n",
    "\n",
    "            precision_vec, recall_vec, _ = precision_recall_curve(y_validation_set, y_predicted_proba[:, 1])\n",
    "            draw_results['precision_vec'].append(precision_vec)\n",
    "            draw_results['recall_vec'].append(recall_vec)\n",
    "        \n",
    "        return folds_results, draw_results\n",
    "\n",
    "    def draw_plot(self, draw_results, final_result, user_c):\n",
    "        #colors = cycle(['cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange', 'red', 'violet', 'fuchsia', 'sienna'])\n",
    "        colors = ['cyan', 'indigo', 'seagreen', 'yellow', 'blue', 'darkorange', 'red', 'violet', 'fuchsia', 'sienna']\n",
    "        lw = 1\n",
    "        plt.clf()\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3))\n",
    "        print \"{}------------------------------------\".format(user_c)\n",
    "        for i in draw_results:\n",
    "            for fpr, tpr in zip(i['fpr'], i['tpr']):\n",
    "                ax1.plot(fpr, tpr, lw=lw)\n",
    "            for recall_vec, precision_vec in zip(i['recall_vec'], i['precision_vec']):\n",
    "                ax2.plot(recall_vec, precision_vec, lw=lw)\n",
    "        ax1.set_xlabel('FPR')\n",
    "        ax1.set_ylabel('TPR')\n",
    "        ax1.set_color_cycle(colors)\n",
    "        ax1.set_title('C={0}, Average AUC={1:0.2f}'.format(user_c, final_result['auc']))\n",
    "        ax1.set_ylim([0.0, 1.05])\n",
    "        ax1.set_xlim([0.0, 1.0])\n",
    "        ax2.set_xlabel('Recall')\n",
    "        ax2.set_ylabel('Precision')\n",
    "        ax2.set_color_cycle(colors)\n",
    "        ax2.set_title('C={0}, Average AUPR={1:0.2f}'.format(user_c, final_result['aupr']))\n",
    "        ax2.set_ylim([0.0, 1.05])\n",
    "        ax2.set_xlim([0.0, 1.0])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    def average_result(self, folds_results):\n",
    "        avg_result = dict()\n",
    "        avg_result['avg_acc'] = sum(folds_results['acc']) / len(folds_results['acc'])\n",
    "        avg_result['avg_auc'] = sum(folds_results['auc']) / len(folds_results['auc'])\n",
    "        avg_result['avg_aupr'] = sum(folds_results['aupr']) / len(folds_results['aupr'])\n",
    "        avg_result['avg_sn'] = sum(folds_results['sn']) / len(folds_results['sn'])\n",
    "        avg_result['avg_sp'] = sum(folds_results['sp']) / len(folds_results['sp'])\n",
    "        avg_result['avg_precision'] = sum(folds_results['precision']) / len(folds_results['precision'])\n",
    "        avg_result['avg_recall'] = sum(folds_results['recall']) / len(folds_results['recall'])\n",
    "        avg_result['sum_confusion_matrix'] = sum(folds_results['confusion_matrix'])\n",
    "\n",
    "        return avg_result\n",
    "\n",
    "\n",
    "    def independent_results(self, param_result):\n",
    "        indep_results = {'indep_acc':[], 'indep_auc':[], 'indep_aupr':[], 'indep_confusion_matrix':[],\n",
    "                         'indep_sn':[], 'indep_sp':[], 'indep_precision':[], 'indep_recall':[]}\n",
    "        for fold in param_result:\n",
    "            indep_results['indep_acc'].append(fold['avg_acc'])\n",
    "            indep_results['indep_auc'].append(fold['avg_auc'])\n",
    "            indep_results['indep_aupr'].append(fold['avg_aupr'])\n",
    "            indep_results['indep_sn'].append(fold['avg_sn'])\n",
    "            indep_results['indep_sp'].append(fold['avg_sp'])\n",
    "            indep_results['indep_precision'].append(fold['avg_precision'])\n",
    "            indep_results['indep_recall'].append(fold['avg_recall'])\n",
    "            indep_results['indep_confusion_matrix'].append(fold['sum_confusion_matrix'])\n",
    "        return indep_results\n",
    "\n",
    "    def final_results (self, indep_results):\n",
    "        results = {'acc':[], 'auc':[], 'aupr':[], 'confusion_matrix':[],\n",
    "                   'sn':[], 'sp':[], 'precision':[], 'recall':[]}\n",
    "        results['acc'] = sum(indep_results['indep_acc']) / len(indep_results['indep_acc'])\n",
    "        results['auc'] = sum(indep_results['indep_auc']) / len(indep_results['indep_auc'])\n",
    "        results['aupr'] = sum(indep_results['indep_aupr']) / len(indep_results['indep_aupr'])\n",
    "        results['sn'] = sum(indep_results['indep_sn']) / len(indep_results['indep_sn'])\n",
    "        results['sp'] = sum(indep_results['indep_sp']) / len(indep_results['indep_sp'])\n",
    "        results['precision'] = sum(indep_results['indep_precision']) / len(indep_results['indep_precision'])\n",
    "        results['recall'] = sum(indep_results['indep_recall']) / len(indep_results['indep_recall'])\n",
    "        results['confusion_matrix'] = sum(indep_results['indep_confusion_matrix'])\n",
    "        return results\n",
    "\n",
    "    def final_results (self,indep_results):\n",
    "        results = {'acc':[], 'auc':[], 'aupr':[], 'confusion_matrix':[],\n",
    "                   'sn':[], 'sp':[], 'precision':[], 'recall':[]}\n",
    "        results['acc'] = sum(indep_results['indep_acc']) / len(indep_results['indep_acc'])\n",
    "        results['auc'] = sum(indep_results['indep_auc']) / len(indep_results['indep_auc'])\n",
    "        results['aupr'] = sum(indep_results['indep_aupr']) / len(indep_results['indep_aupr'])\n",
    "        results['sn'] = sum(indep_results['indep_sn']) / len(indep_results['indep_sn'])\n",
    "        results['sp'] = sum(indep_results['indep_sp']) / len(indep_results['indep_sp'])\n",
    "        results['precision'] = sum(indep_results['indep_precision']) / len(indep_results['indep_precision'])\n",
    "        results['recall'] = sum(indep_results['indep_recall']) / len(indep_results['indep_recall'])\n",
    "        results['confusion_matrix'] = sum(indep_results['indep_confusion_matrix'])\n",
    "        return results\n",
    "    def write_output(self, fd, write_results, user_c):\n",
    "        fd.write(\"C={}-------------------------------------------------\\r\\n\".format(user_c))\n",
    "        fd.write(\"Accuracy avg : {}\\r\\n\".format(write_results['acc']))\n",
    "        fd.write(\"AUC avg : {}\\r\\n\".format(write_results['auc']))\n",
    "        fd.write(\"  Sensitivity avg : {}\\r\\n\".format(write_results['sn']))\n",
    "        fd.write(\"  Specificity avg : {}\\r\\n\".format(write_results['sp']))\n",
    "        fd.write(\"AUPR avg : {}\\r\\n\".format(write_results['aupr']))\n",
    "        fd.write(\"  Precision avg : {}\\r\\n\".format(write_results['precision']))\n",
    "        fd.write(\"  Recall avg : {}\\r\\n\".format(write_results['recall']))\n",
    "        fd.write(\"confusion amtrix : {}\\r\\n\".format(write_results['confusion_matrix']))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def SVM_independent_graph(self, X, y, indep_X, indep_y, param):\n",
    "\n",
    "        folds_results = dict()\n",
    "        draw_results = {'fpr':[], 'tpr':[], 'precision_vec':[], 'recall_vec':[]}\n",
    "\n",
    "        classifier = SVC(C=param['c'], kernel= param['kernel'], degree=param['degree'], probability=True, cache_size=1000)\n",
    "        classifier.fit(X, y)\n",
    "        indep_y_predicted_proba = classifier.predict_proba(indep_X)\n",
    "        indep_y_predicted_label = classifier.predict(indep_X)\n",
    "\n",
    "        # Accuracy\n",
    "        indep_acc = classifier.score(indep_X, indep_y)\n",
    "        folds_results['acc']=indep_acc\n",
    "\n",
    "        # AUC\n",
    "        indep_auc = roc_auc_score(indep_y, indep_y_predicted_proba[:,1])\n",
    "        folds_results['auc']=indep_auc\n",
    "\n",
    "        # Sensitivity, Specificity\n",
    "        indep_sn, indep_sp, support = sensitivity_specificity_support(indep_y, indep_y_predicted_label)\n",
    "        folds_results['sn']=indep_sn\n",
    "        folds_results['sp']=indep_sp\n",
    "\n",
    "        # AUPR\n",
    "        indep_aupr = average_precision_score(indep_y, indep_y_predicted_proba[:,1])\n",
    "        folds_results['aupr']=indep_aupr\n",
    "\n",
    "        # Precision, Recall\n",
    "        indep_precision, indep_recall, _, _ = precision_recall_fscore_support(indep_y, indep_y_predicted_label, average = 'binary')\n",
    "        folds_results['precision']=indep_precision\n",
    "        folds_results['recall']=indep_recall\n",
    "\n",
    "        # Confusion Matirx\n",
    "        indep_confusion_matirx = confusion_matrix(indep_y, indep_y_predicted_label)\n",
    "        folds_results['confusion_matrix']=indep_confusion_matirx\n",
    "\n",
    "        # draw graph\n",
    "        indep_fpr, indep_tpr, thresholds = roc_curve(indep_y, indep_y_predicted_proba[:, 1], pos_label=1)\n",
    "        draw_results['fpr'].append(indep_fpr)\n",
    "        draw_results['tpr'].append(indep_tpr)\n",
    "\n",
    "        indep_precision_vec, indep_recall_vec, _ = precision_recall_curve(indep_y, indep_y_predicted_proba[:, 1])\n",
    "        draw_results['precision_vec'].append(indep_precision_vec)\n",
    "        draw_results['recall_vec'].append(indep_recall_vec)\n",
    "\n",
    "        return folds_results, draw_results\n",
    "    \n",
    "    def indep_average_result(self, folds_results):\n",
    "        avg_result = dict()\n",
    "        avg_result['acc'] = sum(folds_results['acc']) / len(folds_results['acc'])\n",
    "        avg_result['auc'] = sum(folds_results['auc']) / len(folds_results['auc'])\n",
    "        avg_result['aupr'] = sum(folds_results['aupr']) / len(folds_results['aupr'])\n",
    "        avg_result['sn'] = sum(folds_results['sn']) / len(folds_results['sn'])\n",
    "        avg_result['sp'] = sum(folds_results['sp']) / len(folds_results['sp'])\n",
    "        avg_result['precision'] = sum(folds_results['precision']) / len(folds_results['precision'])\n",
    "        avg_result['recall'] = sum(folds_results['recall']) / len(folds_results['recall'])\n",
    "        avg_result['confusion_matrix'] = sum(folds_results['confusion_matrix'])\n",
    "\n",
    "        return avg_result\n",
    "\n",
    "    def seperate_results(self, indep_results):\n",
    "        temp_results = {'acc':[], 'auc':[], 'aupr':[], 'confusion_matrix':[], 'sn':[], 'sp':[], 'precision':[], 'recall':[]}\n",
    "        for i in range(independent_count):\n",
    "            temp_results['acc'].append(indep_results[i]['acc'])\n",
    "            temp_results['auc'].append(indep_results[i]['auc'])\n",
    "            temp_results['aupr'].append(indep_results[i]['aupr'])\n",
    "            temp_results['confusion_matrix'].append(indep_results[i]['confusion_matrix'])\n",
    "            temp_results['sn'].append(indep_results[i]['sn'])\n",
    "            temp_results['sp'].append(indep_results[i]['sp'])\n",
    "            temp_results['precision'].append(indep_results[i]['precision'])\n",
    "            temp_results['recall'].append(indep_results[i]['recall'])\n",
    "        return temp_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
